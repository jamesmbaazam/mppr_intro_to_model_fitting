# Advanced Methods

------------------------------------------------------------------------

## Beyond Least Squares and MLE

[**Why We Need Advanced Methods:**]{style="color: tomato;"}

-   Parameter identifiability issues
-   Complex error structures
-   Model uncertainty
-   Computational challenges
-   Real-time fitting requirements

------------------------------------------------------------------------

## Advanced Approaches

1.  **Bayesian Methods** (MCMC)
2.  **Particle Filtering**
3.  **Approximate Bayesian Computation (ABC)**
4.  **Ensemble Methods**

------------------------------------------------------------------------

## Bayesian Methods: MCMC

[**Core Idea:**]{style="color: #FFFF00;"} Treat parameters as random variables with prior distributions

**Bayes' Theorem:** $$P(\theta | \mathbf{y}) = \frac{P(\mathbf{y} | \theta) P(\theta)}{P(\mathbf{y})}$$

------------------------------------------------------------------------

## Advantages

-   Natural uncertainty quantification
-   Incorporates prior knowledge
-   Handles parameter identifiability
-   Model comparison via Bayes factors

------------------------------------------------------------------------

## Example with Stan

```{r mcmc-example, echo=TRUE, eval=FALSE}
#| code-line-numbers: "3-15|17-24|26-30|32-40|42-47|49-52"  
# Stan model for SIR fitting
"
// SIR model in Stan (walkthrough)                                        
// Functions block: derivative of [S, I, R]                               
functions {
  vector SIR(real t, vector y, array[] real theta) {                      
    real S = y[1]; real I = y[2]; real R = y[3];
    real beta = theta[1]; real gamma = theta[2];
    vector[3] dydt;
    dydt[1] = -beta * S * I;
    dydt[2] =  beta * S * I - gamma * I;
    dydt[3] =  gamma * I;
    return dydt;
  }
}

// Data block: obs counts & time grid                                     
data {
  int<lower=1> n_obs;
  int<lower=1> n_pop;
  array[n_obs] int y;
  real t0;
  array[n_obs] real ts;
}

// Parameters: beta, gamma, S0                                             
parameters {
  array[2] real<lower=0> theta;     // {beta, gamma}
  real<lower=0,upper=1> S0;         // initial susceptible fraction
}

// Transformed params: ODE solve + Poisson rate                            
transformed parameters {
  vector[3] y_init;
  array[n_obs] vector[3] y_hat;
  array[n_obs] real lambda;
  y_init[1] = S0; y_init[2] = 1 - S0; y_init[3] = 0;
  y_hat = ode_rk45(SIR, y_init, t0, ts, theta);
  for (i in 1:n_obs) lambda[i] = y_hat[i, 2] * n_pop;
}

// Model: priors + likelihood                                             
model {
  theta ~ lognormal(0, 1);
  S0    ~ beta(1, 1);
  y     ~ poisson(lambda);
}

// GQ: derived R0                                                          
generated quantities {
  real R_0 = theta[1] / theta[2];
}
"
```

------------------------------------------------------------------------

## Particle Filtering

[**Core Idea:**]{style="color: #FFFF00;"} Sequential Monte Carlo method for state-space models

**When to Use:**

-   Real-time parameter estimation
-   State estimation in stochastic models
-   Handling of missing data
-   Time-varying parameters

------------------------------------------------------------------------

## Advantages

-   Handles stochasticity naturally
-   Real-time updates
-   No assumption of constant parameters
-   Robust to model misspecification

------------------------------------------------------------------------

## Example Application

```{r particle-filter, echo=TRUE, eval=FALSE}
# Particle filter for SIR model
library(pomp)

# Define SIR model with stochasticity
sir_pomp <- pomp(
  data = data.frame(time = covid_times, cases = covid_observed),
  times = "time",
  t0 = 0,
  rprocess = euler.sim(
    step.fun = "sir_step",
    delta.t = 0.1
  ),
  rmeasure = "cases_measure",
  dmeasure = "cases_dmeasure",
  initializer = "sir_init",
  paramnames = c("beta", "gamma", "sigma"),
  statenames = c("S", "I", "R")
)

# Run particle filter
pf <- pfilter(sir_pomp, Np = 1000, params = c(beta = 0.3, gamma = 0.1, sigma = 1))
```

------------------------------------------------------------------------

## Approximate Bayesian Computation (ABC)

[**Core Idea:**]{style="color: #FFFF00;"} Approximate posterior without likelihood evaluation

**When to Use:**

-   Complex likelihoods
-   Intractable models
-   High-dimensional parameter spaces
-   Model comparison

------------------------------------------------------------------------

**Algorithm:**

1.  Sample parameters from prior
2.  Simulate data from model
3.  Compare simulated to observed data
4.  Accept if distance \< threshold

------------------------------------------------------------------------

**Advantages:**

-   No likelihood required
-   Handles complex models
-   Model comparison
-   Intuitive approach

------------------------------------------------------------------------

## Ensemble Methods

[**Core Idea:**]{style="color: #FFFF00;"} Combine multiple models or methods

**Types:**

-   **Model Ensembles**: Average predictions from different models
-   **Method Ensembles**: Combine LS, MLE, MCMC results
-   **Bootstrap Ensembles**: Multiple fits with resampled data

------------------------------------------------------------------------

## Advantages:

-   Reduces overfitting
-   Quantifies model uncertainty
-   More robust predictions
-   Handles model selection uncertainty
